{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras library\n",
    "import keras\n",
    "#import image datagenerator library\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smartbridge\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#defining imagedatagenerator class\n",
    "#it gives augmentation(extra facilities to entities) to dataset\n",
    "#defining image data generator class for train_set\n",
    "\n",
    "#shear range: 'Shear' means that the image will be distorted along an \n",
    "#axis, mostly to create or rectify the perception angles. It's usually \n",
    "#used to augment images so that computers can see how humans see things \n",
    "#from different angles.\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   width_shift_range=.2,\n",
    "                                   height_shift_range=.2,\n",
    "                                   zca_whitening=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining image data generator class for test_set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img_width=64 #setting default image width size \n",
    "img_height=64 #setting default image height size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3662 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#applying Imagedatagenator functionality to both train_set and test_set of images\n",
    "#using flow from directory method\n",
    "\n",
    "#importing dataset\n",
    "x_train = train_datagen.flow_from_directory(r'./dataset-main/training',\n",
    "                                            target_size=(128,128),\n",
    "                                            batch_size=148,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 734 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#applying Imagedatagenator functionality to both train_set and test_set of images\n",
    "#using flow from directory method\n",
    "\n",
    "#importing dataset\n",
    "x_test = test_datagen.flow_from_directory(r'./dataset-main/testing',\n",
    "                                            target_size=(128,128),\n",
    "                                            batch_size=148,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to define linear initializations import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from tensorflow.keras.layers import Dense\n",
    "# to create a convolution kernel import Convolution2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "# Adding Max pooling Layer\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "# Adding Flatten Layer\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding CNN layers\n",
    "#here 32 is number of feature detectors and 3,3 is size of it\n",
    "#and 64,64 is the size of image and 3 is the channel number\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),\n",
    "                        activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Adding CNN layers\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Adding Max pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flatten Layer\n",
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 127008)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1st hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=172))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2d hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=86))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2d hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding output layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='softmax',units=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the learning process\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "17/17 [==============================] - 777s 46s/step - loss: 0.9724 - accuracy: 0.6505 - val_loss: 1.0183 - val_accuracy: 0.6431\n",
      "Epoch 2/8\n",
      "17/17 [==============================] - 806s 48s/step - loss: 0.9493 - accuracy: 0.6655 - val_loss: 0.8900 - val_accuracy: 0.6866\n",
      "Epoch 3/8\n",
      "17/17 [==============================] - 782s 46s/step - loss: 0.9027 - accuracy: 0.6805 - val_loss: 0.8803 - val_accuracy: 0.6907\n",
      "Epoch 4/8\n",
      "17/17 [==============================] - 779s 46s/step - loss: 0.8788 - accuracy: 0.6922 - val_loss: 0.8423 - val_accuracy: 0.7125\n",
      "Epoch 5/8\n",
      "17/17 [==============================] - 768s 45s/step - loss: 0.8557 - accuracy: 0.6969 - val_loss: 0.8280 - val_accuracy: 0.7112\n",
      "Epoch 6/8\n",
      "17/17 [==============================] - 754s 44s/step - loss: 0.8299 - accuracy: 0.7045 - val_loss: 0.8430 - val_accuracy: 0.7180\n",
      "Epoch 7/8\n",
      "17/17 [==============================] - 3507s 217s/step - loss: 0.8180 - accuracy: 0.7114 - val_loss: 0.8378 - val_accuracy: 0.7193\n",
      "Epoch 8/8\n",
      "17/17 [==============================] - 960s 60s/step - loss: 0.8077 - accuracy: 0.7141 - val_loss: 0.8134 - val_accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b251c2580>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=17,\n",
    "                    epochs=8,\n",
    "                    validation_data=x_test,\n",
    "                    validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 172)               21845548  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 86)                14878     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 220       \n",
      "=================================================================\n",
      "Total params: 21,865,283\n",
      "Trainable params: 21,865,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('diabetic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy library\n",
    "import numpy as np\n",
    "#import load_model method to load our saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "#import image from keras.preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "#loading our saved model file\n",
    "model = load_model(\"diabetic.h5\")\n",
    "img = image.load_img(r\"D:\\Rammohan\\AI ML Projects\\Diabetic\\dataset-main\\training\\4\\3b232b394e4f.png\",\n",
    "                     target_size=(128,128))\n",
    "\n",
    "x=image.img_to_array(img) #converting in to array format\n",
    "\n",
    "x=np.expand_dims(x,axis=0) #changing its dimensions as per our requirement \n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021B1C434700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['0', '1', '2', '3', '4']\n",
    "result = str(index[a[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
